{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regular Expressions**\n",
    "\n",
    "If we want to represent a group of strings according to a particular format/pattern, then we should use **Regular Expressions**.\n",
    "\n",
    "Regular Expressions (Regex) provide a declarative mechanism to represent a group of strings according to a particular format or pattern.\n",
    "\n",
    "### **Examples:**\n",
    "1. Writing a regular expression to represent all mobile numbers.\n",
    "2. Writing a regular expression to represent all email IDs.\n",
    "\n",
    "### **Applications of Regular Expressions:**\n",
    "1. **Validation Frameworks/Logic:** Used to develop validation rules for inputs.\n",
    "2. **Pattern Matching Applications:** Examples include `Ctrl+F` in Windows or `grep` in UNIX.\n",
    "3. **Translators:** Useful in developing compilers, interpreters, etc.\n",
    "4. **Digital Circuits:** Used for designing circuits based on specific patterns.\n",
    "5. **Communication Protocols:** Helps in creating protocols like TCP/IP, UDP, etc.\n",
    "\n",
    "### **Using Regular Expressions in Python:**\n",
    "We can develop regular expression-based applications in Python using the `re` module. This module provides several inbuilt functions that make working with regular expressions easier in Python applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **compile()**  \n",
    "   The `re` module contains the `compile()` function to compile a pattern into a RegexObject.  \n",
    "   Example:  \n",
    "   ```python\n",
    "   pattern = re.compile(\"ab\")\n",
    "   ```\n",
    "\n",
    "2. **finditer()**  \n",
    "   Returns an Iterator object which yields a Match object for every match.  \n",
    "   Example:  \n",
    "   ```python\n",
    "   matcher = pattern.finditer(\"abaababa\")\n",
    "   ```\n",
    "\n",
    "   On the Match object, the following methods can be called:\n",
    "   - **start()**: Returns the start index of the match.\n",
    "   - **end()**: Returns the end+1 index of the match.\n",
    "   - **group()**: Returns the matched string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compiler Phases**\n",
    "\n",
    "The standard compiler phases are:\n",
    "\n",
    "1.  **Lexical Analysis (Scanning/Tokenization):** This is the first phase. It reads the source code as a stream of characters and groups them into meaningful units called *tokens*. These tokens represent things like keywords, identifiers, operators, and literals. Regular expressions (REs) are heavily used in this phase to define the patterns for these tokens.\n",
    "\n",
    "2.  **Syntax Analysis (Parsing):** This phase takes the stream of tokens produced by the lexical analyzer and constructs a parse tree (or syntax tree). This tree represents the grammatical structure of the program.\n",
    "\n",
    "3.  **Semantic Analysis:** This phase checks the program for semantic errors, such as type mismatches and undeclared variables. It also gathers type information for subsequent phases.\n",
    "\n",
    "4.  **Intermediate Code Generation:** The compiler generates an intermediate representation of the source code, which is easier to manipulate and optimize than the original source code.\n",
    "\n",
    "5.  **Code Optimization:** This phase attempts to improve the intermediate code so that the generated target code will be more efficient (e.g., faster or smaller).\n",
    "\n",
    "6.  **Target Code Generation:** The final phase generates the target code, which is typically machine code or assembly language.\n",
    "\n",
    "### **Role of Regular Expressions (REs)**\n",
    "\n",
    "The diagram specifically emphasizes the role of REs in **Lexical Analysis**. REs provide a concise and powerful way to specify the patterns for tokens. The lexical analyzer uses these patterns to identify and classify tokens in the source code.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "*   The RE `[a-zA-Z][a-zA-Z0-9]*` could be used to define the pattern for identifiers (variable names).\n",
    "*   The RE `[0-9]+` could be used to define the pattern for integer literals.\n",
    "\n",
    "\n",
    "\n",
    "`Lexical Analysis (using REs) --> Tokenization/Scanning --> (Input to) Syntax Analysis (Parsing)`\n",
    "\n",
    "The other compiler phases (Semantic Analysis, Intermediate Code Generation, Code Optimization, and Target Code Generation) are shown as subsequent steps but are not directly related to the use of REs in the diagram's context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern=re.compile('ab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher=pattern.finditer('abaababbaac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0------2\n",
      "3------5\n",
      "5------7\n",
      "total no of occurences: 3\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for match in matcher:\n",
    "    count+=1\n",
    "    print(f\"{match.start()}------{match.end()}\")\n",
    "print(f\"total no of occurences: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0------2-----ab\n",
      "3------5-----ab\n",
      "5------7-----ab\n",
      "total no of occurences: 3\n"
     ]
    }
   ],
   "source": [
    "pattern=re.compile('ab')\n",
    "matcher=pattern.finditer('abaababbaac')\n",
    "count=0\n",
    "for match in matcher:\n",
    "    count+=1\n",
    "    print(f\"{match.start()}------{match.end()}-----{match.group()}\")\n",
    "print(f\"total no of occurences: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0------1-----a\n",
      "1------2-----b\n",
      "2------3-----a\n",
      "3------4-----a\n",
      "4------5-----b\n",
      "5------6-----a\n",
      "6------7-----b\n",
      "7------8-----b\n",
      "8------9-----a\n",
      "9------10-----a\n",
      "10------11-----c\n",
      "total no of occurences: 11\n"
     ]
    }
   ],
   "source": [
    "pattern=re.compile('[a-z]')\n",
    "matcher=pattern.finditer('abaababbaac')\n",
    "count=0\n",
    "for match in matcher:\n",
    "    count+=1\n",
    "    print(f\"{match.start()}------{match.end()}-----{match.group()}\")\n",
    "print(f\"total no of occurences: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2------3-----6\n",
      "7------8-----3\n",
      "12------13-----2\n",
      "total no of occurences: 3\n"
     ]
    }
   ],
   "source": [
    "pattern=re.compile('[0-9]')\n",
    "matcher=pattern.finditer('ab6aaba3bbaa2c')\n",
    "count=0\n",
    "for match in matcher:\n",
    "    count+=1\n",
    "    print(f\"{match.start()}------{match.end()}-----{match.group()}\")\n",
    "print(f\"total no of occurences: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
